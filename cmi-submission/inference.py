#!/usr/bin/env python3
"""
CMI â€“ Detect Behavior with Sensor Data
--------------------------------------
æ¨ç†è„šæœ¬ï¼ˆCode Competition ç‰ˆæœ¬ï¼‰

æ­¤ç‰ˆæœ¬ä¸ºåˆå¹¶ç‰ˆæœ¬ï¼Œæ•´åˆäº†ä»¥ä¸‹æµç¨‹ï¼š
- ä½¿ç”¨é«˜çº§ç‰¹å¾å·¥ç¨‹ (feature_engineering)
- é‡‡ç”¨â€œå…ˆæ ‡å‡†åŒ–åPaddingâ€çš„æ­£ç¡®æ•°æ®å¤„ç†æµç¨‹
- æ”¯æŒå¤šæ¨¡æ€æ¨¡å‹ (MultimodalityModel)
- ä½¿ç”¨ ColumnTransformer è¿›è¡Œç»Ÿä¸€çš„ç‰¹å¾ç¼©æ”¾

ç›®å½•ç»“æ„::
    cmi-submission/
        data_utils/
            __init__.py
            data_preprocessing.py   â† æ ¸å¿ƒé¢„å¤„ç†é€»è¾‘åœ¨æ­¤
            tof_utils.py
        models/
            __init__.py
            multimodality.py        â† å¤šæ¨¡æ€æ¨¡å‹åœ¨æ­¤
        weights/
            model_fold_1_full.pth â€¦
            scaler_fold_1_full.pkl  â† æ¯ä¸ªæŠ˜å å¯¹åº”ä¸€ä¸ªColumnTransformer
            label_encoder_full.pkl
        inference.py                â† å½“å‰æ–‡ä»¶
"""

import os
import pickle
import warnings
from typing import List, Tuple

import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
import polars as pl
from scipy.spatial.transform import Rotation as R

warnings.filterwarnings("ignore")

# ------------------ è·¯å¾„å¸¸é‡ ------------------
BASE_DIR   = os.path.dirname(__file__)
WEIGHT_DIR = os.path.join(BASE_DIR, "weights")

# ------------------ è‡ªå®šä¹‰æ¨¡å— ------------------
# ä»zsbåˆ†æ”¯å¼•å…¥å¤šæ¨¡æ€æ¨¡å‹
from models.multimodality import MultimodalityModel 
# ä»ä½ çš„åˆ†æ”¯(HEAD)å¼•å…¥æ ¸å¿ƒé¢„å¤„ç†é€»è¾‘å’Œå¸¸é‡
from data_utils.data_preprocessing import pad_sequences, feature_engineering, STATIC_FEATURE_COLS
from data_utils.tof_utils import interpolate_tof

# ------------------ å…¨å±€èµ„æºåŠ è½½ ------------------
# æˆ‘ä»¬æ”¯æŒä¸¤ç§å˜ä½“: "full" (ä½¿ç”¨ THM/TOF ä¼ æ„Ÿå™¨) å’Œ "imu" (ä»…IMU).
# æ¯ç§å˜ä½“éƒ½æœ‰å…¶è‡ªå·±çš„scalerå’Œæ¨¡å‹æƒé‡æ–‡ä»¶ã€‚

MAP_NON_TARGET = "Drink from bottle/cup"

def _load_preprocessing_objects(variant: str):
    """
    ä¸ºç»™å®šå˜ä½“åŠ è½½æ ‡ç­¾ç¼–ç å™¨ (label encoder)ã€‚
    """
    le_path = os.path.join(WEIGHT_DIR, f"label_encoder_{variant}.pkl")
    if not os.path.exists(le_path):
        raise FileNotFoundError(f"Label encoder for variant '{variant}' not found at {le_path}")

    with open(le_path, "rb") as f:
        le = pickle.load(f)
    
    return le

def _load_models(device, num_classes, variant: str):
    """
    åŠ è½½å¤šæ¨¡æ€æ¨¡å‹åŠå…¶åŒ¹é…çš„ ColumnTransformer scalersã€‚
    è¿”å›ä¸€ä¸ª (model, scaler) å…ƒç»„çš„åˆ—è¡¨ã€‚
    é€‚ç”¨äº K-Fold é›†æˆå’Œå•ä¸€æ¨¡å‹æäº¤ã€‚
    """
    pairs = []
    model_cfg_once = None  # To store the config from the first loaded model

    # é¦–å…ˆæŸ¥æ‰¾ K-Fold æ¨¡å‹
    fold_paths = [os.path.join(WEIGHT_DIR, f"model_fold_{i}_{variant}.pth") for i in range(1, 6)]
    fold_paths = [p for p in fold_paths if os.path.exists(p)]

    if fold_paths:
        print(f"ğŸ§©  [{variant}] Detected {len(fold_paths)} fold models â†’ ensemble")
        for p in fold_paths:
            basename = os.path.basename(p)
            parts = basename.split("_")
            fold_num = int(parts[2])  # e.g. model_fold_3_full.pth â†’ 3

            # <--- æ ¸å¿ƒæ”¹åŠ¨ï¼šåŠ è½½ä¸æ¯ä¸ªæ¨¡å‹å¯¹åº”çš„å•ä¸ª ColumnTransformer scaler
            scaler_path = os.path.join(WEIGHT_DIR, f"scaler_fold_{fold_num}_{variant}.pkl")
            if not os.path.exists(scaler_path):
                raise FileNotFoundError(f"Missing scaler for fold {fold_num} ({variant}): {scaler_path}")
            
            with open(scaler_path, "rb") as f:
                scaler = pickle.load(f)

            # ä½¿ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„é…ç½®æ„å»ºæ¨¡å‹
            ckpt = torch.load(p, map_location=device)
            if isinstance(ckpt, dict) and 'model_cfg' in ckpt:
                model_cfg = ckpt['model_cfg']
                if model_cfg_once is None:
                    model_cfg_once = model_cfg  # Save the config
                
                # ç§»é™¤'type'é”®ï¼Œå› ä¸ºå®ƒç”¨äºæ³¨å†Œè¡¨ï¼Œè€Œä¸æ˜¯æ„é€ å‡½æ•°
                init_kwargs = {k: v for k, v in model_cfg.items() if k != 'type'}
                state_dict = ckpt['state_dict']
                model = MultimodalityModel(**init_kwargs)
                
                # ç§»é™¤ torch.compile äº§ç”Ÿçš„ `_orig_mod.` å‰ç¼€
                is_compiled = any(key.startswith('_orig_mod.') for key in state_dict.keys())
                if is_compiled:
                    print("Model was trained with torch.compile(). Cleaning state_dict keys...")
                    from collections import OrderedDict
                    new_state_dict = OrderedDict()
                    for k, v in state_dict.items():
                        name = k.replace('_orig_mod.', '', 1) 
                        new_state_dict[name] = v
                    model.load_state_dict(new_state_dict)
                else:
                    model.load_state_dict(state_dict)
            else:
                raise ValueError(f"Checkpoint for {p} is in a legacy format without 'model_cfg'. Please retrain and save with model config.")

            model.to(device).eval()
            model = torch.compile(model, mode="reduce-overhead")
            pairs.append((model, scaler))
    else:
        print(f"No K-Fold models found")

    if not pairs:
        raise FileNotFoundError(f"No valid models found for variant '{variant}'.")
        
    return pairs, model_cfg_once

print("ğŸ”§  Initialising inference resources â€¦")
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {DEVICE}")

VARIANTS = ["full", "imu"]
RESOURCES = {}

for v in VARIANTS:
    try:
        le = _load_preprocessing_objects(v)
        num_classes = len(le.classes_)
        model_scaler_pairs, model_cfg = _load_models(DEVICE, num_classes, v)

        RESOURCES[v] = {
            "label_encoder": le,
            "num_classes": num_classes,
            "model_scaler_pairs": model_scaler_pairs,
            "model_cfg": model_cfg  # Store the model config
        }
        print(f"âœ…  Resources for '{v}' variant loaded successfully.")
    except FileNotFoundError as e:
        print(f"âš ï¸  Could not load resources for '{v}' variant: {e}. This variant will be unavailable.")

print("âœ…  Resource initialization complete. Ready for inference.")


# ------------------ å•åºåˆ—é¢„å¤„ç† ------------------
def _decide_variant(seq_df: "pd.DataFrame") -> str:
    """
    å¦‚æœ THM æˆ– TOF åˆ—ä¸­çš„æ‰€æœ‰è¡Œéƒ½æ˜¯ NaN/-1ï¼Œåˆ™è¿”å› 'imu'ï¼Œå¦åˆ™è¿”å› 'full'ã€‚
    """
    thm_cols = [c for c in seq_df.columns if c.startswith("thm_")]
    tof_cols = [c for c in seq_df.columns if c.startswith("tof_")]

    if not thm_cols and not tof_cols:
        return "imu"
    
    thm_all_missing = True
    if thm_cols:
        thm_df = seq_df[thm_cols].replace(-1.0, np.nan)
        thm_all_missing = not thm_df.notna().values.any()
    
    tof_all_missing = True
    if tof_cols:
        tof_df = seq_df[tof_cols].replace(-1.0, np.nan)
        tof_all_missing = not tof_df.notna().values.any()
    
    if (thm_cols and thm_all_missing) or (tof_cols and tof_all_missing):
        return "imu"
        
    return "full"

def preprocess_single_sequence(seq_pl: pl.DataFrame, demog_pl: pl.DataFrame):
    """
    é€šè¿‡åº”ç”¨å®Œæ•´çš„ ToF å’Œ IMU ç‰¹å¾å·¥ç¨‹æµç¨‹æ¥é¢„å¤„ç†å•ä¸ªåºåˆ—ï¼Œ
    ç¡®ä¿å®ƒä¸è®­ç»ƒè¿‡ç¨‹å®Œå…¨åŒ¹é…ã€‚
    """
    seq_df = seq_pl.to_pandas()
    if not demog_pl.is_empty():
        seq_df = seq_df.merge(demog_pl.to_pandas(), on="subject", how="left")

    variant = _decide_variant(seq_df)
    
    if variant not in RESOURCES:
        raise FileNotFoundError(f"Resources for variant '{variant}' not available. Ensure models and scalers are exported for this variant.")
    else:
        print(f"ğŸ§¬ Preprocessing with variant: {variant}")

    # 1. é¦–å…ˆï¼Œå¦‚æœéœ€è¦ï¼Œå¤„ç†æ‰€æœ‰ ToF æ’å€¼ã€‚
    if variant != "imu":
        seq_df = interpolate_tof(seq_df)

    # 2. æ¥ä¸‹æ¥ï¼Œåº”ç”¨é«˜çº§ç‰¹å¾å·¥ç¨‹ã€‚
    processed_df, feature_cols = feature_engineering(seq_df)

    # --- ï¼ï¼ï¼å…³é”®ä¿®å¤ï¼šå°†é™æ€ç‰¹å¾åˆ—æ·»åŠ å›æ€»ç‰¹å¾åˆ—è¡¨ï¼ï¼ï¼ ---
    # æ‰¾å‡ºæ•°æ®ä¸­å®é™…å­˜åœ¨çš„é™æ€åˆ—
    existing_static_cols = [c for c in STATIC_FEATURE_COLS if c in processed_df.columns]
    
    # å°†å®ƒä»¬æ·»åŠ åˆ° feature_cols åˆ—è¡¨ä¸­ï¼Œå¹¶å»é‡
    for col in existing_static_cols:
        if col not in feature_cols:
            feature_cols.append(col)
    # -----------------------------------------------------------------

    # 3. å¦‚æœç¡®å®šçš„å˜ä½“æ˜¯ä»…IMUï¼Œåˆ™å†æ¬¡ç¡®è®¤è¿‡æ»¤
    if variant == "imu":
        imu_engineered_cols = [c for c in feature_cols if not (c.startswith("thm_") or c.startswith("tof_"))]
        demographic_cols = [c for c in STATIC_FEATURE_COLS if c in processed_df.columns]
        feature_cols = sorted(list(set(imu_engineered_cols + demographic_cols)))

    # 4. è¿”å›æœ€ç»ˆçš„ç‰¹å¾DataFrameï¼Œå®ƒç°åœ¨åŒ…å«äº†æ‰€æœ‰scaleréœ€è¦çš„åˆ—
    #    å¹¶ç¡®ä¿åˆ—çš„é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼ˆè™½ç„¶ColumnTransformerä¸å¼ºæ±‚é¡ºåºï¼Œä½†è¿™æ˜¯ä¸ªå¥½ä¹ æƒ¯ï¼‰
    final_features_df = processed_df.sort_values("sequence_counter")
    
    # ç¡®ä¿è¿”å›çš„DataFrameåªåŒ…å«feature_colsä¸­çš„åˆ—ï¼Œå¹¶æŒ‰æ­¤é¡ºåºæ’åˆ—
    final_features_df = final_features_df[[c for c in feature_cols if c in final_features_df.columns]]

    return variant, final_features_df


# ------------------ é¢„æµ‹é€»è¾‘ ------------------
def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:
    """
    Entry point that Kaggle calls for each sequence.
    """
    if sequence.is_empty():
        return MAP_NON_TARGET

    # 1. é¢„å¤„ç†åºåˆ—ä»¥è·å¾—ä¸€ä¸ªæœªå¡«å……çš„ã€å¾…æ ‡å‡†åŒ–çš„ç‰¹å¾DataFrame
    variant, features_df = preprocess_single_sequence(sequence, demographics)

    res                  = RESOURCES[variant]
    le                   = res["label_encoder"]
    model_scaler_pairs   = res["model_scaler_pairs"]
    num_cls              = res["num_classes"]
    # âœ¨ Get sequence length dynamically from the model's config
    model_cfg            = res["model_cfg"]
    sequence_length      = model_cfg['sequence_length']

    with torch.no_grad():
        probs_sum = np.zeros((1, num_cls))
        
        # 2. å¾ªç¯éå†æ¯ä¸ªæ¨¡å‹åŠå…¶å¯¹åº”çš„ ColumnTransformer scaler
        for model, scaler in model_scaler_pairs:
            
            # 3. âœ¨ æ ‡å‡†åŒ–: å¯¹æ•´ä¸ªç‰¹å¾DataFrameåº”ç”¨scaler
            X_scaled_unpadded = scaler.transform(features_df)
            scaled_feature_names = scaler.get_feature_names_out()

            # 4. âœ¨ æ‹†åˆ†å¤šæ¨¡æ€æ•°æ® (åœ¨æ ‡å‡†åŒ–ä¹‹å)
            static_cols = [c for c in scaled_feature_names if c in STATIC_FEATURE_COLS]
            tof_cols   = [c for c in scaled_feature_names if c.startswith('tof_')]
            thm_cols   = [c for c in scaled_feature_names if c.startswith('thm_')]
            imu_cols   = [c for c in scaled_feature_names if (c not in static_cols and not c.startswith('tof_') and not c.startswith('thm_'))]

            static_idx = [list(scaled_feature_names).index(c) for c in static_cols]
            tof_idx    = [list(scaled_feature_names).index(c) for c in tof_cols]
            thm_idx    = [list(scaled_feature_names).index(c) for c in thm_cols]
            imu_idx    = [list(scaled_feature_names).index(c) for c in imu_cols]

            static_arr = X_scaled_unpadded[:, static_idx]
            tof_arr    = X_scaled_unpadded[:, tof_idx]
            thm_arr    = X_scaled_unpadded[:, thm_idx]
            imu_arr    = X_scaled_unpadded[:, imu_idx]

            # 5. âœ¨ åˆ†åˆ«å¯¹ IMU å’Œ THM è¿›è¡Œ Padding å¹¶ç”Ÿæˆ mask
            X_imu_pad, imu_mask = pad_sequences([imu_arr], max_length=sequence_length)
            X_thm_pad, thm_mask = pad_sequences([thm_arr], max_length=sequence_length)
            X_tof_pad, _                = pad_sequences([tof_arr], max_length=sequence_length)
            X_static                    = static_arr[0:1, :]  # é™æ€ç‰¹å¾å–ç¬¬ä¸€è¡Œå³å¯

            # 6. è½¬æ¢ä¸ºTensorå¹¶é¢„æµ‹
            xb_imu     = torch.from_numpy(X_imu_pad.astype(np.float32)).to(DEVICE)
            xb_thm     = torch.from_numpy(X_thm_pad.astype(np.float32)).to(DEVICE)
            xb_tof     = torch.from_numpy(X_tof_pad.astype(np.float32)).to(DEVICE)
            xb_static  = torch.from_numpy(X_static.astype(np.float32)).to(DEVICE)
            xb_mask    = torch.from_numpy(imu_mask.astype(np.float32)).to(DEVICE)

            # Forward pass through multimodal model
            probs = torch.softmax(model(xb_imu, xb_thm, xb_tof, xb_static, mask=xb_mask), dim=1).cpu().numpy()
            probs_sum += probs

        # Average the probabilities for the ensemble
        probs = probs_sum / len(model_scaler_pairs)

    pred_idx = int(np.argmax(probs, axis=1)[0])
    label    = le.inverse_transform([pred_idx])[0]
    return label if label in le.classes_ else MAP_NON_TARGET


# ------------------ å¯åŠ¨è¯„æµ‹æœåŠ¡å™¨ ------------------
if __name__ == "__main__":
    import kaggle_evaluation.cmi_inference_server as kis
    print("ğŸš€ Starting CMIInferenceServer â€¦")
    inference_server = kis.CMIInferenceServer(predict)
    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):
        inference_server.serve()
    else:
        os.chdir("/kaggle/working")
        inference_server.run_local_gateway(
            data_paths=(
                "/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv",
                "/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv"
            )
        )