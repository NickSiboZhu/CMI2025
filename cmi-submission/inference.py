#!/usr/bin/env python3
"""
CMI â€“ Detect Behavior with Sensor Data
--------------------------------------
æ¨ç†è„šæœ¬ (æœ€ç»ˆæ··åˆæ¨¡å‹ç‰ˆæœ¬ - å·²ä¿®å¤paddingé”™è¯¯)

æ­¤ç‰ˆæœ¬ä¸ºæœ€ç»ˆæ•´åˆç‰ˆï¼ŒåŒ…å«ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š
- åŠ è½½å¹¶è¿è¡Œä¸€ä¸ªæ··åˆ1D+2Dçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ (MultimodalityModel)ã€‚
- åœ¨æ¨ç†æ—¶åŠ¨æ€åœ°ä»æ—¶åŸŸä¿¡å·ç”Ÿæˆé¢‘è°±å›¾ (Spectrograms)ã€‚
- ä½¿ç”¨ä¸æ¯ä¸ªæ¨¡å‹æŠ˜å ç›¸åŒ¹é…çš„é¢„å¤„ç†å™¨ (ColumnTransformer) å’Œé¢‘è°±å›¾ç»Ÿè®¡é‡ (spec_stats)
  æ¥ç¡®ä¿æ•°æ®å¤„ç†ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ã€‚
- å¥å£®åœ°å¤„ç†ä»»æ„é•¿åº¦çš„è¾“å…¥åºåˆ—ï¼ˆè¿‡é•¿åˆ™æˆªæ–­ï¼Œè¿‡çŸ­åˆ™å¡«å……ï¼‰ã€‚
"""

import os
import pickle
import warnings
from typing import List, Tuple

import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
import polars as pl
from scipy.spatial.transform import Rotation as R
from scipy import signal

warnings.filterwarnings("ignore")

# ------------------ è·¯å¾„å¸¸é‡ ------------------
BASE_DIR   = os.path.dirname(__file__)
WEIGHT_DIR = os.path.join(BASE_DIR, "weights")

# ------------------ è‡ªå®šä¹‰æ¨¡å— ------------------
from models.multimodality import MultimodalityModel
from data_utils.data_preprocessing import pad_sequences, feature_engineering, STATIC_FEATURE_COLS, generate_spectrogram
from data_utils.tof_utils import interpolate_tof

# ------------------ å…¨å±€èµ„æºåŠ è½½ ------------------
MAP_NON_TARGET = "Drink from bottle/cup"

def _load_preprocessing_objects(variant: str):
    """ä¸ºç»™å®šå˜ä½“åŠ è½½æ ‡ç­¾ç¼–ç å™¨ (label encoder)ã€‚"""
    le_path = os.path.join(WEIGHT_DIR, f"label_encoder_{variant}.pkl")
    if not os.path.exists(le_path):
        raise FileNotFoundError(f"Label encoder for variant '{variant}' not found at {le_path}")
    with open(le_path, "rb") as f:
        le = pickle.load(f)
    return le

def _load_models(device, variant: str):
    """Load models, their scalers, spectrogram stats, and capture model config (once).

    Additionally, if spec_params were saved during training as
    'spec_params_fold_{i}_{variant}.pkl', load them and return one set.
    """
    triplets = []
    model_cfg_once = None
    spec_params_once = None
    fold_paths = [os.path.join(WEIGHT_DIR, f"model_fold_{i}_{variant}.pth") for i in range(1, 6)]
    fold_paths = [p for p in fold_paths if os.path.exists(p)]

    if not fold_paths:
        print(f"No K-Fold models found for variant '{variant}'. This variant will be unavailable.")
        return [], None
        
    print(f"ğŸ§©  [{variant}] Detected {len(fold_paths)} fold models â†’ ensemble")
    for p in fold_paths:
        basename = os.path.basename(p)
        fold_num = int(basename.split("_")[2])
        
        scaler_path = os.path.join(WEIGHT_DIR, f"scaler_fold_{fold_num}_{variant}.pkl")
        if not os.path.exists(scaler_path):
            raise FileNotFoundError(f"Missing scaler for fold {fold_num} ({variant}): {scaler_path}")
        with open(scaler_path, "rb") as f:
            scaler = pickle.load(f)

        spec_stats_path = os.path.join(WEIGHT_DIR, f"spec_stats_fold_{fold_num}_{variant}.pkl")
        if not os.path.exists(spec_stats_path):
            raise FileNotFoundError(f"Missing spectrogram stats for fold {fold_num} ({variant}): {spec_stats_path}")
        with open(spec_stats_path, "rb") as f:
            spec_stats = pickle.load(f)

        # Try to load spectrogram generation params used in training for this fold
        spec_params_path = os.path.join(WEIGHT_DIR, f"spec_params_fold_{fold_num}_{variant}.pkl")
        if spec_params_once is None and os.path.exists(spec_params_path):
            with open(spec_params_path, "rb") as f:
                spec_params_once = pickle.load(f)

        ckpt = torch.load(p, map_location=device)
        if 'model_cfg' not in ckpt:
            raise ValueError(f"Checkpoint for {p} is missing 'model_cfg'. Please retrain.")
        model_cfg = {k: v for k, v in ckpt['model_cfg'].items() if k != 'type'}
        if model_cfg_once is None:
            model_cfg_once = model_cfg
        state_dict = ckpt['state_dict']
        
        model = MultimodalityModel(**model_cfg)
        
        is_compiled = any(key.startswith('_orig_mod.') for key in state_dict.keys())
        if is_compiled:
            from collections import OrderedDict
            state_dict = OrderedDict((k.replace('_orig_mod.', '', 1), v) for k, v in state_dict.items())
        model.load_state_dict(state_dict, strict=True)

        model.to(device).eval()
        try:
            model = torch.compile(model, mode="reduce-overhead")
        except Exception as e:
            print(f"âš ï¸  torch.compile failed during inference setup: {e}")

        triplets.append((model, scaler, spec_stats))
    return triplets, model_cfg_once, spec_params_once

# REMOVED: _load_spec_params_for_variant function
# We now strictly require spec_params to be loaded from weights directory

print("ğŸ”§  Initialising inference resources â€¦")
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {DEVICE}")

VARIANTS = ["full", "imu"]
RESOURCES = {}

for v in VARIANTS:
    try:
        le = _load_preprocessing_objects(v)
        model_scaler_stats_triplets, model_cfg_once, spec_params_from_model = _load_models(DEVICE, v)
        if model_scaler_stats_triplets:
            # STRICT: Require spec_params from weights (no config fallback)
            if spec_params_from_model is None:
                raise FileNotFoundError(
                    f"spec_params not found in weights for variant '{v}'. "
                    f"Please retrain with the updated train.py that saves spec_params."
                )
            spec_params = spec_params_from_model
            # Ensure sequence length used for padding matches the trained model
            seq_len_from_model = model_cfg_once['sequence_length'] if model_cfg_once and 'sequence_length' in model_cfg_once else spec_params['max_length']
            spec_params['max_length'] = seq_len_from_model
            RESOURCES[v] = {
                "label_encoder": le,
                "model_scaler_stats_triplets": model_scaler_stats_triplets,
                "spec_params": spec_params,
                "sequence_length": seq_len_from_model,
            }
            print(f"âœ…  Resources for '{v}' variant loaded successfully.")
            print(f"    Using spec_params from training: nperseg={spec_params['nperseg']}, noverlap={spec_params['noverlap']}")
    except FileNotFoundError as e:
        print(f"âš ï¸  Could not load resources for '{v}' variant: {e}.")

print("âœ…  Resource initialization complete. Ready for inference.")

def _decide_variant(seq_df: "pd.DataFrame") -> str:
    """å¦‚æœ THM æˆ– TOF æ•°æ®ç¼ºå¤±ï¼Œåˆ™è¿”å› 'imu'ï¼Œå¦åˆ™è¿”å› 'full'ã€‚"""
    thm_cols = [c for c in seq_df.columns if c.startswith("thm_")]
    tof_cols = [c for c in seq_df.columns if c.startswith("tof_")]
    if not thm_cols and not tof_cols: return "imu"
    thm_all_missing = not seq_df[thm_cols].notna().values.any() if thm_cols else True
    tof_all_missing = not seq_df[tof_cols].notna().values.any() if tof_cols else True
    return "imu" if thm_all_missing and tof_all_missing else "full"

def preprocess_single_sequence(seq_pl: pl.DataFrame, demog_pl: pl.DataFrame):
    """åº”ç”¨å®Œæ•´çš„ç‰¹å¾å·¥ç¨‹æµç¨‹æ¥é¢„å¤„ç†å•ä¸ªåºåˆ—ã€‚"""
    seq_df = seq_pl.to_pandas()
    if not demog_pl.is_empty():
        seq_df = seq_df.merge(demog_pl.to_pandas(), on="subject", how="left")

    variant = _decide_variant(seq_df)
    
    if variant not in RESOURCES:
        raise FileNotFoundError(f"Resources for variant '{variant}' not available. Ensure models and scalers are exported for this variant.")
    else:
        print(f"ğŸ§¬ Preprocessing with variant: {variant}")

    if variant != "imu":
        seq_df = interpolate_tof(seq_df)

    processed_df, feature_cols = feature_engineering(seq_df)

    existing_static_cols = [c for c in STATIC_FEATURE_COLS if c in processed_df.columns]
    for col in existing_static_cols:
        if col not in feature_cols:
            feature_cols.append(col)

    if variant == "imu":
        feature_cols = [c for c in feature_cols if not (c.startswith("thm_") or c.startswith("tof_"))]

    final_features_df = processed_df.sort_values("sequence_counter")
    final_features_df = final_features_df[[c for c in feature_cols if c in final_features_df.columns]]

    return variant, final_features_df


# ------------------ é¢„æµ‹é€»è¾‘ ------------------
def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:
    """Kaggleä¸ºæ¯ä¸ªåºåˆ—è°ƒç”¨çš„å…¥å£ç‚¹ã€‚"""
    if sequence.is_empty():
        return MAP_NON_TARGET

    variant, features_df = preprocess_single_sequence(sequence, demographics)
    
    if variant not in RESOURCES:
        raise RuntimeError(f"Attempted to predict with variant '{variant}', but its resources were not loaded successfully at startup.")

    res = RESOURCES[variant]
    le = res["label_encoder"]
    model_scaler_stats_triplets = res["model_scaler_stats_triplets"]
    spec_params = res["spec_params"]
    sequence_length = res["sequence_length"]

    with torch.no_grad():
        probs_sum = None
        
        for model, scaler, spec_stats in model_scaler_stats_triplets:
            
            # 1. æ ‡å‡†åŒ–æ—¶åŸŸæ•°æ®
            # --- MODIFIED: åœ¨æ­¤å¤„æ·»åŠ  .astype(np.float32) æ¥ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´ ---
            X_scaled_unpadded = scaler.transform(features_df).astype(np.float32)
            
            scaled_feature_names = scaler.get_feature_names_out()

            # 2. æ‹†åˆ†å¤šæ¨¡æ€æ•°æ®
            static_cols = [c for c in scaled_feature_names if c in STATIC_FEATURE_COLS]
            tof_cols = [c for c in scaled_feature_names if c.startswith('tof_')]
            thm_cols = [c for c in scaled_feature_names if c.startswith('thm_')]
            spec_source_cols = ['linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z']
            spec_source_cols = [c for c in spec_source_cols if c in scaled_feature_names]
            imu_cols = [c for c in scaled_feature_names if c not in static_cols + tof_cols + thm_cols]

            static_idx = [list(scaled_feature_names).index(c) for c in static_cols]
            tof_idx = [list(scaled_feature_names).index(c) for c in tof_cols]
            thm_idx = [list(scaled_feature_names).index(c) for c in thm_cols]
            imu_idx = [list(scaled_feature_names).index(c) for c in imu_cols]
            spec_idx = [list(scaled_feature_names).index(c) for c in spec_source_cols]

            static_arr = X_scaled_unpadded[0:1, static_idx]
            tof_arr, thm_arr, imu_arr = X_scaled_unpadded[:, tof_idx], X_scaled_unpadded[:, thm_idx], X_scaled_unpadded[:, imu_idx]
            spec_source_arr = X_scaled_unpadded[:, spec_idx]

            # 3. å¯¹æ—¶åŸŸæ•°æ®è¿›è¡Œ Padding (strict length from trained model)
            X_imu_pad, imu_mask = pad_sequences([imu_arr], max_length=sequence_length)
            X_thm_pad, _ = pad_sequences([thm_arr], max_length=sequence_length)
            X_tof_pad, _ = pad_sequences([tof_arr], max_length=sequence_length)

            # 4. ä»æ ‡å‡†åŒ–çš„æ—¶åŸŸæ•°æ®åŠ¨æ€ç”Ÿæˆå¹¶æ ‡å‡†åŒ–é¢‘è°±å›¾
            sequence_spectrograms = []
            spec_mean, spec_std = spec_stats['mean'], spec_stats['std']
            for i in range(spec_source_arr.shape[1]):
                signal_1d = spec_source_arr[:, i]
                seq_len_current = len(signal_1d)
                if seq_len_current >= sequence_length:
                    padded_signal = signal_1d[-sequence_length:]
                else:
                    padded_signal = np.pad(signal_1d, (sequence_length - seq_len_current, 0), 'constant')
                
                spec = generate_spectrogram(
                    padded_signal,
                    fs=spec_params['fs'],
                    nperseg=spec_params['nperseg'],
                    noverlap=spec_params['noverlap'],
                    max_length=sequence_length,
                )
                spec_norm = (spec - spec_mean) / (spec_std + 1e-6)
                sequence_spectrograms.append(spec_norm)
            
            X_spec = np.stack(sequence_spectrograms, axis=0)[np.newaxis, ...]
            
            # 5. è½¬æ¢ä¸ºTensor (ç”±äºä¸Šæ¸¸å·²æ˜¯float32, è¿™é‡Œç”Ÿæˆçš„ä¹Ÿæ˜¯FloatTensor)
            xb_imu = torch.from_numpy(X_imu_pad).to(DEVICE)
            xb_thm = torch.from_numpy(X_thm_pad).to(DEVICE)
            xb_tof = torch.from_numpy(X_tof_pad).to(DEVICE)
            xb_spec = torch.from_numpy(X_spec).to(DEVICE)
            xb_static = torch.from_numpy(static_arr).to(DEVICE)
            xb_mask = torch.from_numpy(imu_mask).to(DEVICE)

            # 6. ä½¿ç”¨æ··åˆæ¨¡å‹è¿›è¡Œå‰å‘ä¼ æ’­
            probs = torch.softmax(model(xb_imu, xb_thm, xb_tof, xb_spec, xb_static, mask=xb_mask), dim=1).cpu().numpy()
            
            if probs_sum is None: probs_sum = probs
            else: probs_sum += probs

        avg_probs = probs_sum / len(model_scaler_stats_triplets)

    pred_idx = int(np.argmax(avg_probs, axis=1)[0])
    label = le.inverse_transform([pred_idx])[0]
    return label if label in le.classes_ else MAP_NON_TARGET


# ------------------ å¯åŠ¨è¯„æµ‹æœåŠ¡å™¨ ------------------
if __name__ == "__main__":
    import kaggle_evaluation.cmi_inference_server as kis
    print("ğŸš€ Starting CMIInferenceServer â€¦")
    inference_server = kis.CMIInferenceServer(predict)
    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):
        inference_server.serve()
    else:
        # æœ¬åœ°æµ‹è¯•ç½‘å…³
        os.chdir("/kaggle/working")
        inference_server.run_local_gateway(
            data_paths=(
                "/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv",
                "/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv"
            )
        )